# -*- coding: utf-8 -*-
"""cnn_V2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WuJqjdRnBsu1cB3eFX4soXwBL-4MvfCH
"""

# -*- coding: utf-8 -*-

import pickle
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from google.colab import drive
drive.mount('/content/drive')

"""Load saved model"""

from google.colab import files
uploaded = files.upload()

"""Now we load our preprocessed pickle files"""

with open('/content/drive/My Drive/X_data1.pickle', 'rb') as f1:     
    X = pickle.load(f1)

with open('/content/drive/My Drive/y_data1.pickle', 'rb') as f2:
    y = pickle.load(f2)

#TODO: I noticed that there were duplicate images in the data set - these need to
#      be removed and pickle files need to be re-created

"""Here we train our model, in this version we load pre-trained model and check its performance"""

"""Split into training set test set"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

x_train = X_train / 255.0
x_test = X_test / 255.0

"""Convolutional Neural Network Example"""

early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)

"""Here we define our model type and parameters
We are going to skip the following section as our model is pretrained
"""

model = keras.models.Sequential([
    keras.layers.Conv2D(64, (5,5), activation="relu", padding="same",
                        input_shape=[100, 100, 3]),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(8, activation="softmax")
])

"""Now complie the model"""

model.compile(loss="sparse_categorical_crossentropy", optimizer="sgd", metrics=["accuracy"])
# reshape: map data to 4D, with the last dimension of 1 channel (grayscale)

"""and train it"""

history = model.fit(x_train.reshape((x_train.shape[0], 100, 100, 3)), y_train, epochs=10, validation_split=0.1,
                    callbacks=[early_stopping_cb])

model.save("CNNV2.hdf5")



"""Now we call our loaded trained model and check the performance"""

from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model

model2.evaluate(x_test.reshape(x_test.shape[0], 100, 100, 3), y_test)

plt.plot(history.history['accuracy']) #it broke here...  TODO: save the model...
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper left')
plt.show()

"""Test"""

model.evaluate(x_test.reshape(x_test.shape[0], 100, 100, 3), y_test)

plt.plot(model.history['acc'])
plt.plot(model.history['val_acc'])

plt.title('Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.show()

"""Plotting the results"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')

plt.show()

# -*- coding: utf-8 -*- CNN200

import pickle
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras

with open('data_2.pickle', 'rb') as f:
    X = pickle.load(f)
with open('data_y_2.pickle', 'rb') as f:
    y = pickle.load(f)

#Split into training set test set(80% 20%)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

#Normalized
x_train = X_train / 255.0
x_test = X_test / 255.0

#Convolutional Neural Network Example
#activation function = Rectified Linear Unit, ReLU
#ReLU activation for hidden layers
#Means of Early stopping and Dopout are showed on the slide CMT307_Session12.pdf
#some Arguments means of model can be found at https://keras.io/models/sequential/
early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
model = keras.models.Sequential([
    keras.layers.Conv2D(64, 7, activation="relu", padding="same",
                        input_shape=[200, 200, 3]),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10, activation="softmax")
])
model.compile(loss="sparse_categorical_crossentropy", optimizer="sgd", metrics=["accuracy"])
# reshape: map data to 4D, with the last dimension of 1 channel (grayscale)
history = model.fit(x_train.reshape((x_train.shape[0], 200, 200, 3)), y_train, epochs=60, validation_split=0.1,
                    callbacks=[early_stopping_cb])
model.evaluate(x_test.reshape(x_test.shape[0], 200, 200, 3), y_test)

#Test

model.evaluate(x_test.reshape(x_test.shape[0], 200, 200, 3), y_test)

#save

model.save("model-cnn.hdf5")


plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])

plt.title('Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Valid'], loc = 'upper left')

plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Valid'], loc = 'upper left')

plt.show()

# -*- coding: utf-8 -*- Xception 200
"""pre_trained_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11Lzrj6DBDiLPdl8if89MJwNH2f_80s8x

Load data
"""

# load data
import pickle
import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt


with open('data_2.pickle', 'rb') as f:
    X = pickle.load(f)
with open('data_y_2.pickle', 'rb') as f:
    y = pickle.load(f)
#Split data into training, test and validation(75% 15% 10%)
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)
X_valid,X_test,y_valid,y_test = train_test_split(X_test,y_test,test_size=0.4)
#Randomly shuffle data
np.random.seed(200)
np.random.shuffle(X_train)
np.random.seed(200)
np.random.shuffle(X_test)
np.random.seed(200)
np.random.shuffle(y_train)
np.random.seed(200)
np.random.shuffle(y_test)
np.random.seed(200)
np.random.shuffle(X_valid)
np.random.seed(200)
np.random.shuffle(y_valid)

"""Normalized"""

x_train = X_train / 255.0
x_test = X_test / 255.0
x_valid = X_valid / 255.0

#Fine-tuning xception model

#Training with existing layers fixed
#activation function = softmax
#the Arguments means of Xception can be found at https://keras.io/applications/
base_model = keras.applications.xception.Xception(weights="imagenet", include_top=False)
avg = keras.layers.GlobalAveragePooling2D()(base_model.output)
output = keras.layers.Dense(8, activation="softmax")(avg)
model = keras.Model(inputs=base_model.input, outputs=output)
# the Arguments means of optimizers can be found at https://keras.io/optimizers/
for layer in base_model.layers:
  layer.trainable = False
optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)
model.compile(loss="sparse_categorical_crossentropy", optimizer=optimizer, metrics=["accuracy"])
history = model.fit(x_train.reshape((x_train.shape[0], 200, 200, 3)), y_train, epochs=5, validation_data=(x_valid.reshape((x_valid.shape[0], 200, 200, 3)),y_valid))

#The model can be further trained with base layers unfrozen
for layer in base_model.layers:
  layer.trainable = True
#the Arguments means of compile can be found at https://keras.io/models/model/
optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.001)
model.compile(loss="sparse_categorical_crossentropy", optimizer=optimizer, metrics=["accuracy"])
history = model.fit(x_train.reshape((x_train.shape[0], 200, 200, 3)), y_train, epochs=40, validation_data=(x_valid.reshape((x_valid.shape[0], 200, 200, 3)),y_valid))

#Test

model.evaluate(x_test.reshape(x_test.shape[0], 200, 200, 3), y_test)

#save

model.save("model-xception-1.hdf5")

#Draw chart



plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])

plt.title('Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Valid'], loc = 'upper left')

plt.show()


plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Valid'], loc = 'upper left')

plt.show()

# -*- coding: utf-8 -*- CNN100

import pickle
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras

with open('data.pickle', 'rb') as f:
    X = pickle.load(f)
with open('data_y.pickle', 'rb') as f:
    y = pickle.load(f)

"""Split into training set test set"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

x_train = X_train / 255.0
x_test = X_test / 255.0

"""Convolutional Neural Network Example"""

early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
model = keras.models.Sequential([
    keras.layers.Conv2D(64, (5,5), activation="relu", padding="same",
                        input_shape=[100, 100, 3]),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(8, activation="softmax")
])
model.compile(loss="sparse_categorical_crossentropy", optimizer="sgd", metrics=["accuracy"])
# reshape: map data to 4D, with the last dimension of 1 channel (grayscale)
history = model.fit(x_train.reshape((x_train.shape[0], 100, 100, 3)), y_train, epochs=60, validation_split=0.1,
                    callbacks=[early_stopping_cb])
model.evaluate(x_test.reshape(x_test.shape[0], 100, 100, 3), y_test)

"""Test"""

model.evaluate(x_test.reshape(x_test.shape[0], 100, 100, 3), y_test)

"""save"""

model.save("model-cnn.hdf5")


plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])

plt.title('Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')

plt.show()

# -*- coding: utf-8 -*-
"""pre_trained_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11Lzrj6DBDiLPdl8if89MJwNH2f_80s8x

Load data
"""

# load data
import pickle
import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt


with open('data.pickle', 'rb') as f:
    X = pickle.load(f)
with open('data_y.pickle', 'rb') as f:
    y = pickle.load(f)

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)
X_valid,X_test,y_valid,y_test = train_test_split(X_test,y_test,test_size=0.4)
np.random.seed(200)
np.random.shuffle(X_train)
np.random.seed(200)
np.random.shuffle(X_test)
np.random.seed(200)
np.random.shuffle(y_train)
np.random.seed(200)
np.random.shuffle(y_test)
np.random.seed(200)
np.random.shuffle(X_valid)
np.random.seed(200)
np.random.shuffle(y_valid)

"""Normalized"""

x_train = X_train / 255.0
x_test = X_test / 255.0
x_valid = X_valid / 255.0

"""Fine-tuning xception model"""


base_model = keras.applications.xception.Xception(weights="imagenet", include_top=False)
avg = keras.layers.GlobalAveragePooling2D()(base_model.output)
output = keras.layers.Dense(8, activation="softmax")(avg)
model = keras.Model(inputs=base_model.input, outputs=output)

for layer in base_model.layers:
  layer.trainable = False
optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)
model.compile(loss="sparse_categorical_crossentropy", optimizer=optimizer, metrics=["accuracy"])
history = model.fit(x_train.reshape((x_train.shape[0], 100, 100, 3)), y_train, epochs=5, validation_data=(x_valid.reshape((x_valid.shape[0], 100, 100, 3)),y_valid))

# The model can be further trained with base layers unfrozen
for layer in base_model.layers:
  layer.trainable = True

optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.001)
model.compile(loss="sparse_categorical_crossentropy", optimizer=optimizer, metrics=["accuracy"])
history = model.fit(x_train.reshape((x_train.shape[0], 100, 100, 3)), y_train, epochs=40, validation_data=(x_valid.reshape((x_valid.shape[0], 100, 100, 3)),y_valid))

"""Test"""

model.evaluate(x_test.reshape(x_test.shape[0], 100, 100, 3), y_test)

"""save"""

model.save("model-xception.hdf5")

"""Draw chart"""



plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])

plt.title('Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.show()


plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.title('Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')

plt.show()